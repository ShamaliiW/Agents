{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1639bf8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_community'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RunnableLambda\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HumanMessage\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAI\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchains\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLMChain\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PromptTemplate\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects\\AI\\Agents\\Agents\\.venv\\Lib\\site-packages\\langchain\\llms\\__init__.py:545\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m    544\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m545\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m llms\n\u001b[32m    547\u001b[39m     \u001b[38;5;66;03m# If not in interactive env, raise warning.\u001b[39;00m\n\u001b[32m    548\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_interactive_env():\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_community'"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# --- Agent definitions based on your CrewAI specs ---\n",
    "\n",
    "def get_research_analyst():\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"content\"],\n",
    "        template=\"\"\"\n",
    "You are a research analyst conducting an in-depth company research. Follow these instructions carefully:\n",
    "\n",
    "{content}\n",
    "\n",
    "Provide a detailed report including executive summary, company overview, leadership, services, technology stack, recent news, partnerships, strategic focus, opportunities, and verified citations.\n",
    "\"\"\"\n",
    "    )\n",
    "    llm = OpenAI(temperature=0.3)\n",
    "    return LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "def get_content_writer():\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"content\"],\n",
    "        template=\"\"\"\n",
    "You are a content writer tasked with synthesizing research reports into a persuasive, concise, and structured B2B outreach summary.\n",
    "\n",
    "{content}\n",
    "\n",
    "Focus on key facts, strategic goals, technology gaps, suggested outreach angles, and a clear call to action.\n",
    "\"\"\"\n",
    "    )\n",
    "    llm = OpenAI(temperature=0.5)\n",
    "    return LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "def get_prospect_researcher():\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"content\"],\n",
    "        template=\"\"\"\n",
    "You are a market researcher tasked with generating a list of companies likely to need software development services.\n",
    "\n",
    "{content}\n",
    "\n",
    "Output a Markdown table with company name, country, industry, funding stage, and a short rationale.\n",
    "\"\"\"\n",
    "    )\n",
    "    llm = OpenAI(temperature=0.7)\n",
    "    return LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Initialize agents\n",
    "research_agent = get_research_analyst()\n",
    "analysis_agent = get_content_writer()\n",
    "prospect_agent = get_prospect_researcher()\n",
    "\n",
    "# You can add tools here if needed\n",
    "tools = []  # Example: [search_tool]\n",
    "\n",
    "# State class (can be a simple dict)\n",
    "class GraphState(dict):\n",
    "    pass\n",
    "\n",
    "# --- Define graph nodes ---\n",
    "\n",
    "def research_company(state: GraphState) -> GraphState:\n",
    "    company = state.get(\"company_name\", \"Unknown Company\")\n",
    "    prompt_content = f\"\"\"\n",
    "Conduct an in-depth company research on: {company}\n",
    "\n",
    "Steps:\n",
    "1. Use reliable sources (official websites, news articles, LinkedIn, Crunchbase, etc.)\n",
    "2. Identify key company details: overview, services, tech stack, leadership, financials, partnerships\n",
    "3. Analyze strategic direction, market focus, recent developments, and potential software needs\n",
    "4. Cross-verify facts across multiple sources\n",
    "5. Document clearly with citations\n",
    "\"\"\"\n",
    "    result = research_agent.invoke([HumanMessage(content=prompt_content)])\n",
    "    return {\"research_report\": result.content, **state}\n",
    "\n",
    "def analyze_report(state: GraphState) -> GraphState:\n",
    "    research_report = state.get(\"research_report\", \"\")\n",
    "    prompt_content = f\"\"\"\n",
    "Based on the following research report, create a concise, persuasive summary for B2B outreach:\n",
    "\n",
    "{research_report}\n",
    "\n",
    "Focus:\n",
    "- Executive summary (2â€“3 paragraphs)\n",
    "- Key facts and strategic goals (bulleted)\n",
    "- Tech gaps or improvement areas\n",
    "- Suggested outreach/collaboration angle\n",
    "- Call to action for marketing team\n",
    "\n",
    "Make it clean, structured, and pitch-ready.\n",
    "\"\"\"\n",
    "    result = analysis_agent.invoke([HumanMessage(content=prompt_content)])\n",
    "    return {\"company_brief\": result.content, **state}\n",
    "\n",
    "def generate_prospect_list(state: GraphState) -> GraphState:\n",
    "    prompt_content = \"\"\"\n",
    "Generate a list of at least 50 global companies likely to need software development services.\n",
    "\n",
    "Focus sectors:\n",
    "- Fintech, Healthtech, Edtech, Logistics, AI startups, Recently funded companies\n",
    "\n",
    "For each company include:\n",
    "- Name\n",
    "- Country\n",
    "- Industry\n",
    "- Funding Stage (if known)\n",
    "- One-line reason why they might need software development\n",
    "\n",
    "Output as a Markdown table.\n",
    "\"\"\"\n",
    "    result = prospect_agent.invoke([HumanMessage(content=prompt_content)])\n",
    "    return {\"prospect_list\": result.content, **state}\n",
    "\n",
    "# --- Build LangGraph workflow ---\n",
    "\n",
    "graph = StateGraph(GraphState)\n",
    "\n",
    "graph.add_node(\"research\", RunnableLambda(research_company))\n",
    "graph.add_node(\"analyze\", RunnableLambda(analyze_report))\n",
    "graph.add_node(\"prospect\", RunnableLambda(generate_prospect_list))\n",
    "\n",
    "graph.set_entry_point(\"research\")\n",
    "graph.add_edge(\"research\", \"analyze\")\n",
    "graph.add_edge(\"analyze\", END)\n",
    "\n",
    "# Prospect runs in parallel with research/analyze\n",
    "graph.add_parallel_edges(\"research\", [\"prospect\"])\n",
    "graph.add_edge(\"prospect\", END)\n",
    "\n",
    "compiled_graph = graph.compile()\n",
    "\n",
    "# --- Run the workflow ---\n",
    "\n",
    "initial_state = {\n",
    "    \"company_name\": \"Stripe\"\n",
    "}\n",
    "\n",
    "result = compiled_graph.invoke(initial_state)\n",
    "\n",
    "print(\"----- Company Brief -----\\n\")\n",
    "print(result.get(\"company_brief\", \"No output\"))\n",
    "print(\"\\n----- Prospect List -----\\n\")\n",
    "print(result.get(\"prospect_list\", \"No output\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
